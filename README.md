# Automated Data Pipeline Testing using Python & PySpark

## Overview
This project demonstrates automated testing of data pipelines built using Python and PySpark on Azure Databricks.
The focus is on validating data accuracy, completeness, and consistency across ETL workflows.

## Tools & Technologies
- Python
- PySpark
- SQL
- Azure Databricks
- Git & GitHub
- Jira
- Agile Methodology

## Project Scope
- Reviewed ETL workflows and user stories to understand end-to-end pipeline logic
- Designed and executed automated data validation checks
- Performed source-to-target validation using SQL
- Tested scheduled Databricks jobs for functional and regression scenarios
- Logged and tracked defects using Jira

## Test Scenarios Covered
- Record count validation
- Null and duplicate checks
- Data reconciliation between source and target
- Regression testing after pipeline updates

## Folder Structure
